"use strict";(self.webpackChunksuse_edge_docs=self.webpackChunksuse_edge_docs||[]).push([[2278],{7548:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>l,toc:()=>c});var t=i(5893),r=i(1151);const s={sidebar_position:6,title:"*Draft* Feature Configuration"},o="SUSE Adaptive Telco Infrastructure Platform (ATIP)",l={id:"product/atip/features",title:"*Draft* Feature Configuration",description:"SUSE ATIP is a platform designed for hosting modern, cloud native, Telco applications at scale from core to edge.",source:"@site/docs/product/atip/features.md",sourceDirName:"product/atip",slug:"/product/atip/features",permalink:"/docs/product/atip/features",draft:!1,unlisted:!1,editUrl:"https://github.com/suse-edge/suse-edge.github.io/tree/main/docs/product/atip/features.md",tags:[],version:"current",lastUpdatedBy:"Alberto Morgante Medina",lastUpdatedAt:1690382815,formattedLastUpdatedAt:"Jul 26, 2023",sidebarPosition:6,frontMatter:{sidebar_position:6,title:"*Draft* Feature Configuration"},sidebar:"atip",previous:{title:"*Draft* Edge Site Installation",permalink:"/docs/product/atip/edge-site"},next:{title:"*Draft* Lifecycle Actions",permalink:"/docs/product/atip/lifecycle"}},a={},c=[{value:"Bios configuration",id:"bios-configuration",level:2},{value:"Kernel Real Time",id:"kernel-real-time",level:2},{value:"CPU Tuned Configuration",id:"cpu-tuned-configuration",level:2},{value:"Multus + Calico",id:"multus--calico",level:2},{value:"SRIOV",id:"sriov",level:2},{value:"Option 1 - Installation of SR-IOV CNI device plugins and a config map to configure it properly",id:"option-1---installation-of-sr-iov-cni-device-plugins-and-a-config-map-to-configure-it-properly",level:3},{value:"Prepare the config map for the device plugin",id:"prepare-the-config-map-for-the-device-plugin",level:4},{value:"Prepare the daemonset for the device plugin",id:"prepare-the-daemonset-for-the-device-plugin",level:4},{value:"Option 2 - Installation using Rancher using Helm chart for SR-IOV CNI and device plugins",id:"option-2---installation-using-rancher-using-helm-chart-for-sr-iov-cni-and-device-plugins",level:3},{value:"Get helm if not present",id:"get-helm-if-not-present",level:4},{value:"Install SRIOV",id:"install-sriov",level:4},{value:"Check the  deployed resources crd and pods",id:"check-the--deployed-resources-crd-and-pods",level:4},{value:"Check the label in the nodes",id:"check-the-label-in-the-nodes",level:4},{value:"Review the daemonset to see the new <code>sriov-network-config-daemon</code> and <code>sriov-rancher-nfd-worker</code> as active and ready",id:"review-the-daemonset-to-see-the-new-sriov-network-config-daemon-and-sriov-rancher-nfd-worker-as-active-and-ready",level:4},{value:"Check the interfaces detected",id:"check-the-interfaces-detected",level:4},{value:"Create the NetworkNode Policy to configure the VFs",id:"create-the-networknode-policy-to-configure-the-vfs",level:4},{value:"Validate configurations",id:"validate-configurations",level:4},{value:"Create the sriov network (Optional, in case we need a different network):",id:"create-the-sriov-network-optional-in-case-we-need-a-different-network",level:4},{value:"DPDK",id:"dpdk",level:2},{value:"Kernel parameters",id:"kernel-parameters",level:3},{value:"Load vfio-pci kernel module",id:"load-vfio-pci-kernel-module",level:3},{value:"Create VFs from the NICs",id:"create-vfs-from-the-nics",level:3},{value:"Bind the new VFs with the vfio-pci driver",id:"bind-the-new-vfs-with-the-vfio-pci-driver",level:3},{value:"Review the configuration applied:",id:"review-the-configuration-applied",level:3},{value:"Huge Pages",id:"huge-pages",level:2},{value:"Kernel parameters",id:"kernel-parameters-1",level:3},{value:"Usage of huge pages",id:"usage-of-huge-pages",level:3},{value:"CPU Pinning Configuration",id:"cpu-pinning-configuration",level:2},{value:"Requirements",id:"requirements",level:3},{value:"Use CPU Pinning on kubernetes",id:"use-cpu-pinning-on-kubernetes",level:3},{value:"NUMA Aware scheduling",id:"numa-aware-scheduling",level:2},{value:"Identify NUMA nodes",id:"identify-numa-nodes",level:3},{value:"VRAN Acceleration (Intel ACC100)",id:"vran-acceleration-intel-acc100",level:2},{value:"Kernel parameters",id:"kernel-parameters-2",level:3},{value:"Load igb_uio and vfio-pci kernel modules",id:"load-igb_uio-and-vfio-pci-kernel-modules",level:3},{value:"Get interface information Acc100",id:"get-interface-information-acc100",level:3},{value:"Bind the PF with igb_uio module",id:"bind-the-pf-with-igb_uio-module",level:3},{value:"Create the VFs from the PF",id:"create-the-vfs-from-the-pf",level:3},{value:"Configure acc100 with the proposed configuration file",id:"configure-acc100-with-the-proposed-configuration-file",level:3},{value:"Check the new VFs created from the FEC PF:",id:"check-the-new-vfs-created-from-the-fec-pf",level:3},{value:"Metal LB (Beta)",id:"metal-lb-beta",level:2}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"suse-adaptive-telco-infrastructure-platform-atip",children:"SUSE Adaptive Telco Infrastructure Platform (ATIP)"}),"\n",(0,t.jsx)(n.p,{children:"SUSE ATIP is a platform designed for hosting modern, cloud native, Telco applications at scale from core to edge."}),"\n",(0,t.jsx)(n.p,{children:"This section documents how to configuration telco specific features on ATIP deployed clusters"}),"\n",(0,t.jsx)(n.p,{children:"We will cover the next topics:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#bios-configuration",children:"Bios configuration"}),": Bios configuration to be used by the real time kernel to optimize the performance in the hardware."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#kernel-image-for-real-time",children:"Kernel image for Real Time"}),": Kernel image to be used by the real time kernel."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#cpu-tuned-configuration",children:"CPU Tuned configuration"}),": Tuned configuration to be used by the real time kernel."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#multus--calico",children:"Multus-Calico configuration"}),": Multus configuration to be used by the kubernetes cluster."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#sriov",children:"SRIOV configuration"}),": SRIOV configuration to be used by the kubernetes workloads."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#dpdk",children:"DPDK configuration"}),": DPDK configuration to be used by system."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#huge-pages",children:"Huge Pages"}),": Huge Pages configuration to be used by the kubernetes workloads."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#cpu-pinning-configuration",children:"CPU Pinning configuration"}),": CPU Pinning configuration to be used by the kubernetes workloads."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#numa-aware-scheduling",children:"NUMA Aware scheduling configuration"}),": NUMA Aware scheduling configuration to be used by the kubernetes workloads."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#metal-lb-configuration",children:"Metal LB configuration"}),": Metal LB configuration to be used by the kubernetes workloads."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"bios-configuration",children:"Bios configuration"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Note"}),": This configuration depends on the hardware vendor, so please, check with your hardware vendor the best configuration to be used."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"This section is really important to optimize the performance of the real time kernel in the hardware, because some of this parameters could increase not limiting the performance of the real time kernel.\nThe next table shows the recommended configuration for the most common hardware vendors:"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Option"}),(0,t.jsx)(n.th,{children:"Value"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Workload Profile"}),(0,t.jsx)(n.td,{children:"Telco Optimized"}),(0,t.jsx)(n.td,{children:"Telco profile to optimize the performance in the hardware."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Boot Performance Mode"}),(0,t.jsx)(n.td,{children:"Max. Performance"}),(0,t.jsx)(n.td,{children:"Maximize the performance in the boot process."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Hyper- Threading (Logical Proccesor)"}),(0,t.jsx)(n.td,{children:"Enable"}),(0,t.jsx)(n.td,{children:"This option enables Intel\xae Hyper-Threading Technology for logical processor enabling and converting processor cores (pCores) to logical cores (lCores)."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Virtualization Technology (XAPIC)"}),(0,t.jsx)(n.td,{children:"Enable"}),(0,t.jsx)(n.td,{children:"This option is for Extended Advanced Programmable Interrupt Controller (xAPIC) support for the Intel\xae Virtualization Technology for Directed I/O (Intel\xae VT-d) feature."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"uncore frequency scaling"}),(0,t.jsx)(n.td,{children:"Disable"}),(0,t.jsx)(n.td,{children:"If enabled, Uncore Frequency Scaling (UFS) allows the uncore to operate at a lower frequency when the Power Control Unit (PCU) has detected low utilization. Conversely, UFS allows the uncore to operate at a higher frequency when the PCU has detected high utilization."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"CPU P-State Control (EIST PSD Function"}),(0,t.jsx)(n.td,{children:"HW_ALL"}),(0,t.jsx)(n.td,{children:"optimization of the voltage and CPU fequency during operation"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"CPU C-State Control"}),(0,t.jsx)(n.td,{children:"Disable"}),(0,t.jsx)(n.td,{children:"This option is for the CPU C-State Control feature, which provides power savings by placing the processor into lower power states when the processor is idle."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"CPU C1E Support"}),(0,t.jsx)(n.td,{children:"Disable"}),(0,t.jsx)(n.td,{children:"This option is for the CPU Enhanced Halt (C1E) feature, which provides power savings by placing the processor into a low power state when the processor is idle."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"AVX License Pre-Grant"}),(0,t.jsx)(n.td,{children:"Enable"}),(0,t.jsx)(n.td,{children:"If enabled, this option enables the pre-grant license level selection based on workload with the AVX ICCP Pre-Grant Level option."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"AVX ICCP Pre- Grant Level"}),(0,t.jsx)(n.td,{children:"Level 5"}),(0,t.jsx)(n.td,{children:"This option selects a workload level for the Intel\xae Advanced Vector Extensions (Intel\xae AVX): Intel\xae AVX-512 Heavy"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"AVX P1"}),(0,t.jsx)(n.td,{children:"Level 2"}),(0,t.jsx)(n.td,{children:"This option serves a dual purpose: 1 -Specifies the base P1 ratio for Intel\xae Streaming SIMD Extensions (Intel\xae SSE) or Intel\xae AVX workloads. 2- Pre-grants a license level based on the workload level."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Energy Efficient Turbo"}),(0,t.jsx)(n.td,{children:"Disable"}),(0,t.jsx)(n.td,{children:"This option allows entry into the Intel\xae Turbo Boost Technology frequency when the Power Control Unit (PCU) has detected high utilization."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Turbo Mode"}),(0,t.jsx)(n.td,{children:"Enable"}),(0,t.jsx)(n.td,{children:"Enabling this Intel\xae Turbo Boost Technology mode setting allows the CPU cores to operate at higher than the rated frequency."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"GPSS timer"}),(0,t.jsx)(n.td,{children:"0us"}),(0,t.jsx)(n.td,{children:"This option allows the reduction of the Global P-State Selection (GPSS) timer to be set from: 0 \u03bcs to 500 \u03bcs"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"LLC prefetch"}),(0,t.jsx)(n.td,{children:"Enable"}),(0,t.jsx)(n.td,{children:"This option enables Last Level Cache (LLC) hardware prefetch logic."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Frequency Prioritization (RAPL Prioritization)"}),(0,t.jsx)(n.td,{children:"Disable"}),(0,t.jsx)(n.td,{children:"This setting controls whether the Running Average Power Limit (RAPL) balancer is enabled. If enabled, it activates per core power budgeting."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Hardware P-States"}),(0,t.jsx)(n.td,{children:"Native with no Legacy Support"}),(0,t.jsx)(n.td,{children:"When enabled, this option allows the hardware to choose a Performance State (P-State) based on an OS request (that is, a legacy P-State)."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"EPP enable3"}),(0,t.jsx)(n.td,{children:"Disable"}),(0,t.jsx)(n.td,{children:"When this option is enabled, the system uses the energy performance bias register for the Energy Performance Preference (EPP) input to make decision on Performance State (P-State) or Processor Core Idle State (C-State) transitions."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"APS Rocketing"}),(0,t.jsx)(n.td,{children:"Disable"}),(0,t.jsx)(n.td,{children:"Rocketing mechanism in the HWP p-state selection for pcode algorithm. Rocketing enables the core ratio to jump to max turbo instantaneously as opposed to a smooth ramp"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Scalability"}),(0,t.jsx)(n.td,{children:"Disable"}),(0,t.jsx)(n.td,{children:"Core Performance to frequency scalability based on optimizations in the CPU."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Native ASPM"}),(0,t.jsx)(n.td,{children:"Disable"}),(0,t.jsx)(n.td,{children:"ASPM off not controlled by BIOS or OS."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Power Performance Tuning"}),(0,t.jsx)(n.td,{children:"OS Controls EPB"}),(0,t.jsx)(n.td,{children:"This option selects the BIOS or OS that controls the Energy Performance Bias (EPB) functionality."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Workload Configuration"}),(0,t.jsx)(n.td,{children:"I/O sensitive"}),(0,t.jsx)(n.td,{children:"This option allows the system power and performance profile to be set to favor compute intensive workload or I/O sensitive workload."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Dynamic L1"}),(0,t.jsx)(n.td,{children:"Disable"}),(0,t.jsx)(n.td,{children:"This option applies only to the package-level setting to allow dynamically entering the lower power link state L1."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Set Fan Profile"}),(0,t.jsx)(n.td,{children:"Performance"}),(0,t.jsx)(n.td,{children:"This option allows the fan profile to be set to Performance, Balanced, or Quiet."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Cooling Configuration - Fan Speed Offset"}),(0,t.jsx)(n.td,{children:"Medium"}),(0,t.jsx)(n.td,{children:"This option allows the fan speed offset to be set to Low, Medium, or High."})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"kernel-real-time",children:"Kernel Real Time"}),"\n",(0,t.jsx)(n.p,{children:"The real time kernel image is not necessarily better than a standard kernel.\nIt is a different kernel tuned to a specific use case. The real time kernel is tuned for lower latency at the cost of throughput. The real time kernel is not recommended for general purpose use, but in our case, this is the recommended kernel for Telco Workloads."}),"\n",(0,t.jsx)(n.p,{children:"There are 4 top features:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Deterministic Execution:"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Get greater predictability \u2013 ensure critical business processes complete in time, every time and deliver high quality of service, even under heavy system loads. By shielding key system resources for high-priority processes, you can ensure greater predictability for time-sensitive applications."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Low Jitter:"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The low jitter built upon the highly deterministic technology helps to keep applications synchronized with the real world. This helps services that need ongoing and repeated calculation."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Priority Inheritance:"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Priority inheritance refers to the ability of a lower priority process to assume a higher priority when there is a higher priority process that requires the lower priority process to finish before it can accomplish its task. SUSE Linux Enterprise Real Time solves these priority inversion problems for mission-critical processes."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Thread Interrupts:"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Processes running in interrupt mode in a general-purpose operating system are not preemptible. With SUSE Linux Enterprise Real Time these interrupts have been encapsulated by kernel threads, which are interruptible, and in turn allow the hard and soft interrupts to be preempted by user-defined higher priority processes."}),"\n",(0,t.jsx)(n.p,{children:"In our case, if you have installed a real time image like SLE Micro RT, kernel real time is already installed and you don't need to install it again."}),"\n",(0,t.jsxs)(n.p,{children:["You could check it looking for the kernel and see if contains the ",(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"rt"})})," string at the end of the kernel info:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"uname -r\n5.14.21-150400.15.11-rt\n"})}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:["For more information about the real time kernel, please visit ",(0,t.jsx)(n.a,{href:"https://www.suse.com/products/realtime/",children:"https://www.suse.com/products/realtime/"})]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"cpu-tuned-configuration",children:"CPU Tuned Configuration"}),"\n",(0,t.jsx)(n.p,{children:"The first thing is to create a profile for the cpu cores we want to isolate. In this case, we will isolate the cores 1-30 and 33-62."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'echo "export tuned_params" >> /etc/grub.d/00_tuned\n\necho "isolated_cores=1-30,33-62" >> /etc/tuned/cpu-partitioning-variables.conf\n\ntuned-adm profile cpu-partitioning\nCannot talk to Tuned daemon via DBus. Is Tuned daemon running?\nTrying to (re)start tuned...\nTuned (re)started, changes applied.\n'})}),"\n",(0,t.jsx)(n.p,{children:"Then we need to modify grub option to isolate cpu cores as well as another important parameters for the cpu usage."}),"\n",(0,t.jsx)(n.p,{children:"Modify in /etc/default/grub the next line, to add the cpu cores to isolate. The next options are the most important to be customized with your current hardware:"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"parameter"}),(0,t.jsx)(n.th,{children:"value"}),(0,t.jsx)(n.th,{children:"description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"isolcpu"}),(0,t.jsx)(n.td,{children:"1-30,33-62"}),(0,t.jsx)(n.td,{children:"Isolate the cores 1-30 and 33-62"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"skew_tick"}),(0,t.jsx)(n.td,{children:"1"}),(0,t.jsx)(n.td,{children:"This option allows the kernel to skew the timer interrupts across the isolated CPUs."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"nohz"}),(0,t.jsx)(n.td,{children:"on"}),(0,t.jsx)(n.td,{children:"This option allows the kernel to run the timer tick on a single CPU when the system is idle."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"nohz_full"}),(0,t.jsx)(n.td,{children:"1-30,33-62"}),(0,t.jsx)(n.td,{children:"kernel boot parameter is the current main interface to configure full dynticks along with CPU Isolation."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"rcu_nocbs"}),(0,t.jsx)(n.td,{children:"1-30,33-62"}),(0,t.jsx)(n.td,{children:"This option allows the kernel to run the RCU callbacks on a single CPU when the system is idle."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"kthread_cpus"}),(0,t.jsx)(n.td,{children:"0,31,32,63"}),(0,t.jsx)(n.td,{children:"This option allows the kernel to run the kthreads on a single CPU when the system is idle."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"irqaffinity"}),(0,t.jsx)(n.td,{children:"0,31,32,63"}),(0,t.jsx)(n.td,{children:"This option allows the kernel to run the interrupts on a single CPU when the system is idle."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"processor.max_cstate"}),(0,t.jsx)(n.td,{children:"1"}),(0,t.jsx)(n.td,{children:"This option prevents the CPU from dropping into a sleep state when idle"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"intel_idle.max_cstate"}),(0,t.jsx)(n.td,{children:"0"}),(0,t.jsx)(n.td,{children:"This option disables the intel_idle driver and allows acpi_idle to be used"})]})]})]}),"\n",(0,t.jsx)(n.p,{children:"With the values showed above, we are isolating 60 cores, and we are using 4 cores for the OS."}),"\n",(0,t.jsx)(n.p,{children:"Let's modify the grub file with the previous values:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'vi /boot/efi/EFI/sle_rt/grub.cfg\n\tset tuned_params="skew_tick=1 nohz=on nohz_full=1-30,33-62 rcu_nocbs=1-30,33-62 tuned.non_isolcpus=80000001,80000001 nosoftlockup"\n\nvi /etc/default/grub\n    GRUB_CMDLINE_LINUX="intel_iommu=on intel_pstate=passive processor.max_cstate=1 intel_idle.max_cstate=0 iommu=pt usbcore.autosuspend=-1 selinux=0 enforcing=0 nmi_watchdog=0 crashkernel=auto softlockup_panic=0 audit=0 mce=off hugepagesz=1G hugepages=40 hugepagesz=2M hugepages=0 default_hugepagesz=1G kthread_cpus=0,31,32,63 irqaffinity=0,31,32,63 isolcpu=1-30,33-62 skew_tick=1 nohz_full=1-30,33-62 rcu_nocbs=1-30,33-62 rcu_nocb_poll"\n\ntransactional-update grub.cfg\n'})}),"\n",(0,t.jsx)(n.p,{children:"To validate that the parameters are applied after reboot, you could check:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"cat /proc/cmdline\n"})}),"\n",(0,t.jsx)(n.h2,{id:"multus--calico",children:"Multus + Calico"}),"\n",(0,t.jsx)(n.p,{children:"Multus CNI is a CNI plugin that enables attaching multiple network interfaces to pods. Multus does not replace CNI plugins, instead it acts as a CNI plugin multiplexer. Multus is useful in certain use cases, especially when pods are network intensive and require extra network interfaces that support dataplane acceleration techniques such as SR-IOV."}),"\n",(0,t.jsx)(n.p,{children:"Multus can not be deployed standalone. It always requires at least one conventional CNI plugin that fulfills the Kubernetes cluster network requirements. That CNI plugin becomes the default for Multus, and will be used to provide the primary interface for all pods.\nIn our case, most of the workloads in Telco will be deployed using Multus + calico."}),"\n",(0,t.jsx)(n.p,{children:"To enable Multus on RKE2 cluster, add multus as the first list entry in the cni config key, followed by the name of the plugin you want to use alongside Multus (or none if you will provide your own default plugin). Note that multus must always be in the first position of the list. For example, to use Multus with calico as the default plugin you could specify:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"# /etc/rancher/rke2/config.yaml\ncni:\n- multus\n- calico\n"})}),"\n",(0,t.jsxs)(n.p,{children:["This can also be specified with command-line arguments, i.e. ",(0,t.jsx)(n.code,{children:"--cni=multus,calico"})," or ",(0,t.jsx)(n.code,{children:"--cni=multus --cni=calico"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"You could also install Multus directly during the edge cluster installation:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"multus.png",src:i(8122).Z+"",width:"1667",height:"878"})}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:["For more information about Multus, please visit ",(0,t.jsx)(n.a,{href:"https://github.com/k8snetworkplumbingwg/multus-cni",children:"https://github.com/k8snetworkplumbingwg/multus-cni"})]}),"\n",(0,t.jsxs)(n.p,{children:["For more information about CNI plugins, please visit ",(0,t.jsx)(n.a,{href:"https://docs.rke2.io/install/network_options",children:"https://docs.rke2.io/install/network_options"})]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"sriov",children:"SRIOV"}),"\n",(0,t.jsx)(n.p,{children:"SR-IOV allows a device, such as a network adapter, to separate access to its resources among various PCIe hardware functions.\nThere are different ways to deploy SRIOV, and in this case, we will show two different options:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Option 1: using the SRIOV CNI device plugins and a config map to configure it properly."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Option 2: using the SRIOV helm chart from Rancher to make this deployment easy."}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"option-1---installation-of-sr-iov-cni-device-plugins-and-a-config-map-to-configure-it-properly",children:"Option 1 - Installation of SR-IOV CNI device plugins and a config map to configure it properly"}),"\n",(0,t.jsx)(n.h4,{id:"prepare-the-config-map-for-the-device-plugin",children:"Prepare the config map for the device plugin"}),"\n",(0,t.jsx)(n.p,{children:"You could get the information to fill the config map from the lspci command:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"lspci | grep -i acc\n8a:00.0 Processing accelerators: Intel Corporation Device 0d5c\n\nlspci | grep -i net\nxr11-1:~ # lspci | grep -i net\n19:00.0 Ethernet controller: Broadcom Inc. and subsidiaries BCM57504 NetXtreme-E 10Gb/25Gb/40Gb/50Gb/100Gb/200Gb Ethernet (rev 11)\n19:00.1 Ethernet controller: Broadcom Inc. and subsidiaries BCM57504 NetXtreme-E 10Gb/25Gb/40Gb/50Gb/100Gb/200Gb Ethernet (rev 11)\n19:00.2 Ethernet controller: Broadcom Inc. and subsidiaries BCM57504 NetXtreme-E 10Gb/25Gb/40Gb/50Gb/100Gb/200Gb Ethernet (rev 11)\n19:00.3 Ethernet controller: Broadcom Inc. and subsidiaries BCM57504 NetXtreme-E 10Gb/25Gb/40Gb/50Gb/100Gb/200Gb Ethernet (rev 11)\n51:00.0 Ethernet controller: Intel Corporation Ethernet Controller E810-C for QSFP (rev 02)\n51:00.1 Ethernet controller: Intel Corporation Ethernet Controller E810-C for QSFP (rev 02)\n51:01.0 Ethernet controller: Intel Corporation Ethernet Adaptive Virtual Function (rev 02)\n51:01.1 Ethernet controller: Intel Corporation Ethernet Adaptive Virtual Function (rev 02)\n51:01.2 Ethernet controller: Intel Corporation Ethernet Adaptive Virtual Function (rev 02)\n51:01.3 Ethernet controller: Intel Corporation Ethernet Adaptive Virtual Function (rev 02)\n51:11.0 Ethernet controller: Intel Corporation Ethernet Adaptive Virtual Function (rev 02)\n51:11.1 Ethernet controller: Intel Corporation Ethernet Adaptive Virtual Function (rev 02)\n51:11.2 Ethernet controller: Intel Corporation Ethernet Adaptive Virtual Function (rev 02)\n51:11.3 Ethernet controller: Intel Corporation Ethernet Adaptive Virtual Function (rev 02)\n"})}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"0d5d"})," is the VF from the FEC card (take a look that it's different than the lspci | grep acc result, because it's the VF, not the PF). Normally it's the first VF of the card, so the last name will be consecutive after VF creation."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The config map consists of a JSON file that describe devices using filters to discover and creates some groups for the interfaces.\nThe most important is to understand the filters and the groups. The filters are used to discover the devices and the groups are used to create the interfaces."}),"\n",(0,t.jsx)(n.p,{children:"For example, we could filter using:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["vendorID: ",(0,t.jsx)(n.code,{children:"8086"})," (Intel)"]}),"\n",(0,t.jsxs)(n.li,{children:["deviceID: ",(0,t.jsx)(n.code,{children:"0d5d"})," (FEC)"]}),"\n",(0,t.jsxs)(n.li,{children:["driver: ",(0,t.jsx)(n.code,{children:"vfio-pci"})," (SRIOV driver)"]}),"\n",(0,t.jsxs)(n.li,{children:["pfNames: ",(0,t.jsx)(n.code,{children:"p2p1"})," (PF name)"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"We could also set placesholders like:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:'pfNames: ["eth1#1,2,3,4,5,6"]'}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Regarding the groups, we could create a group for the FEC card and another group for the Intel card even creating some prefix depending our use case:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["resourceName: ",(0,t.jsx)(n.code,{children:"pci_sriov_net_bh_dpdk"})]}),"\n",(0,t.jsxs)(n.li,{children:["resourcePrefix: ",(0,t.jsx)(n.code,{children:"Rancher.io"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"There are a lot of combinations in order to discover and create the resource group to allocate some VFs to the pods."}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:["For more information about the filters and groups, please visit ",(0,t.jsx)(n.a,{href:"https://github.com/k8snetworkplumbingwg/sriov-network-device-plugin",children:"https://github.com/k8snetworkplumbingwg/sriov-network-device-plugin"})]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'cat <<EOF | k apply -f -\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: sriovdp-config\n  namespace: kube-system\ndata:\n  config.json: |\n    {\n        "resourceList": [\n            {\n                "resourceName": "intel_fec_5g",\n                "devicetype": "accelerator",\n                "selectors": {\n                    "vendors": ["8086"],\n                    "devices": ["0d5d"]\n                }\n            },\n            {\n                "resourceName": "intel_sriov_odu",\n                "selectors": {\n                    "vendors": ["8086"],\n                    "devices": ["1889"],\n                    "drivers": ["vfio-pci"],\n                    "pfNames": ["p2p1"]\n                }\n            },\n            {\n                "resourceName": "intel_sriov_oru",\n                "selectors": {\n                    "vendors": ["8086"],\n                    "devices": ["1889"],\n                    "drivers": ["vfio-pci"],\n                    "pfNames": ["p2p2"]\n                }\n            }\n        ]\n    }\nEOF\n'})}),"\n",(0,t.jsx)(n.h4,{id:"prepare-the-daemonset-for-the-device-plugin",children:"Prepare the daemonset for the device plugin"}),"\n",(0,t.jsx)(n.p,{children:"No changes are needed in the daemonset, so you can use the same upstream daemonset file."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'cat <<EOF | k apply -f -\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: sriov-device-plugin\n  namespace: kube-system\n\n---\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-sriov-device-plugin-amd64\n  namespace: kube-system\n  labels:\n    tier: node\n    app: sriovdp\nspec:\n  selector:\n    matchLabels:\n      name: sriov-device-plugin\n  template:\n    metadata:\n      labels:\n        name: sriov-device-plugin\n        tier: node\n        app: sriovdp\n    spec:\n      hostNetwork: true\n      nodeSelector:\n        kubernetes.io/arch: amd64\n      tolerations:\n      - key: node-role.kubernetes.io/master\n        operator: Exists\n        effect: NoSchedule\n      serviceAccountName: sriov-device-plugin\n      containers:\n      - name: kube-sriovdp\n        image: ghcr.io/k8snetworkplumbingwg/sriov-network-device-plugin:latest-amd64\n        imagePullPolicy: IfNotPresent\n        args:\n        - --log-dir=sriovdp\n        - --log-level=10\n        securityContext:\n          privileged: true\n        resources:\n          requests:\n            cpu: "250m"\n            memory: "40Mi"\n          limits:\n            cpu: 1\n            memory: "200Mi"\n        volumeMounts:\n        - name: devicesock\n          mountPath: /var/lib/kubelet/\n          readOnly: false\n        - name: log\n          mountPath: /var/log\n        - name: config-volume\n          mountPath: /etc/pcidp\n        - name: device-info\n          mountPath: /var/run/k8s.cni.cncf.io/devinfo/dp\n      volumes:\n        - name: devicesock\n          hostPath:\n            path: /var/lib/kubelet/\n        - name: log\n          hostPath:\n            path: /var/log\n        - name: device-info\n          hostPath:\n            path: /var/run/k8s.cni.cncf.io/devinfo/dp\n            type: DirectoryOrCreate\n        - name: config-volume\n          configMap:\n            name: sriovdp-config\n            items:\n            - key: config.json\n              path: config.json\nEOF\n'})}),"\n",(0,t.jsx)(n.p,{children:"After that you should see the pods running:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"kubectl get pods -n kube-system | grep sriov\nkube-system       kube-sriov-device-plugin-amd64-twjfl                    1/1     Running   0          2m\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Check the interfaces discovered and available in the nodes to be used by the pods:"}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'kubectl get $(kubectl get nodes -oname) -o jsonpath=\'{.status.allocatable}\' | jq\n{\n  "cpu": "64",\n  "ephemeral-storage": "256196109726",\n  "hugepages-1Gi": "40Gi",\n  "hugepages-2Mi": "0",\n  "intel.com/intel_fec_5g": "1",\n  "intel.com/intel_sriov_odu": "4",\n  "intel.com/intel_sriov_oru": "4",\n  "memory": "221396384Ki",\n  "pods": "110"\n}\n'})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["The FEC will be ",(0,t.jsx)(n.code,{children:"intel.com/intel_fec_5g"})," and the value will be 1"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["The VF will be ",(0,t.jsx)(n.code,{children:"intel.com/intel_sriov_odu"})," or ",(0,t.jsx)(n.code,{children:"intel.com/intel_sriov_oru"})," if you deploy it with device plugin and the config map without helm charts"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Important Note"}),": If you don't get the interfaces available here, does not make sense continue with the workload, because interface will not be available for pods"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"option-2---installation-using-rancher-using-helm-chart-for-sr-iov-cni-and-device-plugins",children:"Option 2 - Installation using Rancher using Helm chart for SR-IOV CNI and device plugins"}),"\n",(0,t.jsx)(n.h4,{id:"get-helm-if-not-present",children:"Get helm if not present"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3\nchmod 500 get_helm.sh\n./get_helm.sh\n"})}),"\n",(0,t.jsx)(n.h4,{id:"install-sriov",children:"Install SRIOV"}),"\n",(0,t.jsx)(n.p,{children:"This part could be done in two ways, using the CLI or using the Rancher UI"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Install Operator from CLI"}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"helm repo add rancher-charts https://raw.githubusercontent.com/rancher/charts/dev-v2.7/\nhelm install sriov-crd rancher-charts/sriov-crd\nhelm install sriov rancher-charts/sriov -n kube-system\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Install Operator from Rancher UI"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Once your cluster is installed and you have access to the Rancher UI, you can install the SR-IOV Operator from the Rancher UI from the apps tab:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"sriov.png",src:i(5063).Z+"",width:"1749",height:"914"})}),"\n",(0,t.jsx)(n.h4,{id:"check-the--deployed-resources-crd-and-pods",children:"Check the  deployed resources crd and pods"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"kubectl -n sriov-network-operator get crd"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"kubectl -n sriov-network-operator get pods"})}),"\n",(0,t.jsx)(n.h4,{id:"check-the-label-in-the-nodes",children:"Check the label in the nodes"}),"\n",(0,t.jsx)(n.p,{children:"Now, if you have all resources running, the label should appears automatically in your node:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'kubectl get nodes -oyaml | grep feature.node.kubernetes.io/network-sriov.capable\n    feature.node.kubernetes.io/network-sriov.capable: "true"\n'})}),"\n",(0,t.jsx)(n.p,{children:"if not present, you can add it manually:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"kubectl label $(kubectl get nodes -oname) feature.node.kubernetes.io/network-sriov.capable=true\n"})}),"\n",(0,t.jsxs)(n.h4,{id:"review-the-daemonset-to-see-the-new-sriov-network-config-daemon-and-sriov-rancher-nfd-worker-as-active-and-ready",children:["Review the daemonset to see the new ",(0,t.jsx)(n.code,{children:"sriov-network-config-daemon"})," and ",(0,t.jsx)(n.code,{children:"sriov-rancher-nfd-worker"})," as active and ready"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"kubectl get daemonset -A\nNAMESPACE             NAME                            DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR                                           AGE\ncalico-system         calico-node                     1         1         1       1            1           kubernetes.io/os=linux                                  15h\ncattle-sriov-system   sriov-network-config-daemon     1         1         1       1            1           feature.node.kubernetes.io/network-sriov.capable=true   45m\ncattle-sriov-system   sriov-rancher-nfd-worker        1         1         1       1            1           <none>                                                  45m\nkube-system           rke2-ingress-nginx-controller   1         1         1       1            1           kubernetes.io/os=linux                                  15h\nkube-system           rke2-multus-ds                  1         1         1       1            1           kubernetes.io/arch=amd64,kubernetes.io/os=linux         15h\n"})}),"\n",(0,t.jsx)(n.p,{children:"After some minutes (can take up to 10 min to be updated) the nodes detected and configured will appear:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"kubectl get sriovnetworknodestates.sriovnetwork.openshift.io -A\nNAMESPACE             NAME     AGE\ncattle-sriov-system   xr11-2   83s\n"})}),"\n",(0,t.jsx)(n.h4,{id:"check-the-interfaces-detected",children:"Check the interfaces detected"}),"\n",(0,t.jsx)(n.p,{children:"the interfaces discovered should be the pci address of the network device. Check this information with lspci command in the host."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'$ kubectl get sriovnetworknodestates.sriovnetwork.openshift.io -n kube-system -oyaml\napiVersion: v1\nitems:\n- apiVersion: sriovnetwork.openshift.io/v1\n  kind: SriovNetworkNodeState\n  metadata:\n    creationTimestamp: "2023-06-07T09:52:37Z"\n    generation: 1\n    name: xr11-2\n    namespace: cattle-sriov-system\n    ownerReferences:\n    - apiVersion: sriovnetwork.openshift.io/v1\n      blockOwnerDeletion: true\n      controller: true\n      kind: SriovNetworkNodePolicy\n      name: default\n      uid: 80b72499-e26b-4072-a75c-f9a6218ec357\n    resourceVersion: "356603"\n    uid: e1f1654b-92b3-44d9-9f87-2571792cc1ad\n  spec:\n    dpConfigVersion: "356507"\n  status:\n    interfaces:\n    - deviceID: "1592"\n      driver: ice\n      eSwitchMode: legacy\n      linkType: ETH\n      mac: 40:a6:b7:9b:35:f0\n      mtu: 1500\n      name: p2p1\n      pciAddress: "0000:51:00.0"\n      totalvfs: 128\n      vendor: "8086"\n    - deviceID: "1592"\n      driver: ice\n      eSwitchMode: legacy\n      linkType: ETH\n      mac: 40:a6:b7:9b:35:f1\n      mtu: 1500\n      name: p2p2\n      pciAddress: "0000:51:00.1"\n      totalvfs: 128\n      vendor: "8086"\n    syncStatus: Succeeded\nkind: List\nmetadata:\n  resourceVersion: ""\n'})}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsx)(n.p,{children:"Note: If your interface is not detected here you should ensure that it is present in the next config map"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"kubectl get cm supported-nic-ids -oyaml -n cattle-sriov-system\n"})}),"\n",(0,t.jsx)(n.p,{children:"if your device is not there you have to edit the config map adding the right values to be discovered (should be necessary to restart the daemonset sriov-network-config-daemon)"}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"create-the-networknode-policy-to-configure-the-vfs",children:"Create the NetworkNode Policy to configure the VFs"}),"\n",(0,t.jsxs)(n.p,{children:["Basically, you will create some VFs (",(0,t.jsx)(n.code,{children:"numVfs"}),") from the device (",(0,t.jsx)(n.code,{children:"rootDevices"}),") and will be configured with the driver (",(0,t.jsx)(n.code,{children:"deviceType"}),") and the MTU (",(0,t.jsx)(n.code,{children:"mtu"}),"):"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'cat <<EOF | kubectl apply -f -\napiVersion: sriovnetwork.openshift.io/v1\nkind: SriovNetworkNodePolicy\nmetadata:\n  name: policy-dpdk\n  namespace: kube-system\nspec:\n  nodeSelector:\n    feature.node.kubernetes.io/network-sriov.capable: "true"\n  resourceName: intelnicsDpdk\n  deviceType: vfio-pci\n  numVfs: 8\n  mtu: 1500\n  nicSelector:\n    deviceID: "1592"\n    vendor: "8086"\n    rootDevices:\n    - 0000:51:00.0\nEOF\n'})}),"\n",(0,t.jsx)(n.h4,{id:"validate-configurations",children:"Validate configurations"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'kubectl get $(kubectl get nodes -oname) -o jsonpath=\'{.status.allocatable}\' | jq\n{\n  "cpu": "64",\n  "ephemeral-storage": "256196109726",\n  "hugepages-1Gi": "60Gi",\n  "hugepages-2Mi": "0",\n  "intel.com/intel_fec_5g": "1",\n  "memory": "200424836Ki",\n  "pods": "110",\n  "rancher.io/intelnicsDpdk": "8"\n}\n'})}),"\n",(0,t.jsx)(n.h4,{id:"create-the-sriov-network-optional-in-case-we-need-a-different-network",children:"Create the sriov network (Optional, in case we need a different network):"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'cat <<EOF | k apply -f -\napiVersion: sriovnetwork.openshift.io/v1\nkind: SriovNetwork\nmetadata:\n  name: network-dpdk\n  namespace: kube-system\nspec:\n  ipam: |\n    {\n      "type": "host-local",\n      "subnet": "192.168.0.0/24",\n      "rangeStart": "192.168.0.20",\n      "rangeEnd": "192.168.0.60",\n      "routes": [{\n        "dst": "0.0.0.0/0"\n      }],\n      "gateway": "192.168.0.1"\n    }\n  vlan: 500 \n  resourceName: intelnicsDpdk\nEOF\n'})}),"\n",(0,t.jsx)(n.p,{children:"Check the network created:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'kubectl get network-attachment-definitions.k8s.cni.cncf.io -A -oyaml\n\napiVersion: v1\nitems:\n- apiVersion: k8s.cni.cncf.io/v1\n  kind: NetworkAttachmentDefinition\n  metadata:\n    annotations:\n      k8s.v1.cni.cncf.io/resourceName: rancher.io/intelnicsDpdk\n    creationTimestamp: "2023-06-08T11:22:27Z"\n    generation: 1\n    name: network-dpdk\n    namespace: kube-system\n    resourceVersion: "13124"\n    uid: df7c89f5-177c-4f30-ae72-7aef3294fb15\n  spec:\n    config: \'{ "cniVersion":"0.3.1", "name":"network-dpdk","type":"sriov","vlan":500,"vlanQoS":0,"ipam":{"type":"host-local","subnet":"192.168.0.0/24","rangeStart":"192.168.0.10","rangeEnd":"192.168.0.60","routes":[{"dst":"0.0.0.0/0"}],"gateway":"192.168.0.1"}\n      }\'\nkind: List\nmetadata:\n  resourceVersion: ""\n'})}),"\n",(0,t.jsx)(n.h2,{id:"dpdk",children:"DPDK"}),"\n",(0,t.jsx)(n.h3,{id:"kernel-parameters",children:"Kernel parameters"}),"\n",(0,t.jsx)(n.p,{children:"To use dpdk using some drivers we need to enable some parameters in the kernel:"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"parameter"}),(0,t.jsx)(n.th,{children:"value"}),(0,t.jsx)(n.th,{children:"description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"iommu"}),(0,t.jsx)(n.td,{children:"pt"}),(0,t.jsx)(n.td,{children:"This option allows to use vfio for the dpdk interfaces"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"intel_iommu"}),(0,t.jsx)(n.td,{children:"on"}),(0,t.jsx)(n.td,{children:"This option enables to use vfio for VFs."})]})]})]}),"\n",(0,t.jsx)(n.p,{children:"To enable this parameters we need to add them to the kernel command line:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"vi /etc/default/grub\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'GRUB_CMDLINE_LINUX="intel_iommu=on intel_pstate=passive processor.max_cstate=1 intel_idle.max_cstate=0 iommu=pt usbcore.autosuspend=-1 selinux=0 enforcing=0 nmi_watchdog=0 crashkernel=auto softlockup_panic=0 audit=0 mce=off hugepagesz=1G hugepages=40 hugepagesz=2M hugepages=0 default_hugepagesz=1G kthread_cpus=0,31,32,63 irqaffinity=0,31,32,63 isolcpu=1-30,33-62 skew_tick=1 nohz_full=1-30,33-62 rcu_nocbs=1-30,33-62 rcu_nocb_poll"\n'})}),"\n",(0,t.jsx)(n.p,{children:"Then you need to update the grub configuration and reboot the system to apply the changes:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"transactional-update grub.cfg\nreboot\n"})}),"\n",(0,t.jsx)(n.p,{children:"To validate that the parameters are applied after the reboot you can check the command line:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"cat /proc/cmdline\n"})}),"\n",(0,t.jsx)(n.h3,{id:"load-vfio-pci-kernel-module",children:"Load vfio-pci kernel module"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"modprobe vfio-pci\n"})}),"\n",(0,t.jsx)(n.h3,{id:"create-vfs-from-the-nics",children:"Create VFs from the NICs"}),"\n",(0,t.jsx)(n.p,{children:"To create 4 VFs PCI addresses for example for 2 different NICs we need to execute the following commands:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"echo 4 > /sys/bus/pci/devices/0000:51:00.0/sriov_numvfs\n\necho 4 > /sys/bus/pci/devices/0000:51:00.1/sriov_numvfs\n"})}),"\n",(0,t.jsx)(n.h3,{id:"bind-the-new-vfs-with-the-vfio-pci-driver",children:"Bind the new VFs with the vfio-pci driver"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"dpdk-devbind.py -b vfio-pci 0000:51:01.0 0000:51:01.1 0000:51:01.2 0000:51:01.3 0000:51:11.0 0000:51:11.1 0000:51:11.2 0000:51:11.3\n"})}),"\n",(0,t.jsx)(n.h3,{id:"review-the-configuration-applied",children:"Review the configuration applied:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"dpdk-devbind.py -s\n\nNetwork devices using DPDK-compatible driver\n============================================\n0000:51:01.0 'Ethernet Adaptive Virtual Function 1889' drv=vfio-pci unused=iavf,igb_uio\n0000:51:01.1 'Ethernet Adaptive Virtual Function 1889' drv=vfio-pci unused=iavf,igb_uio\n0000:51:01.2 'Ethernet Adaptive Virtual Function 1889' drv=vfio-pci unused=iavf,igb_uio\n0000:51:01.3 'Ethernet Adaptive Virtual Function 1889' drv=vfio-pci unused=iavf,igb_uio\n0000:51:01.0 'Ethernet Adaptive Virtual Function 1889' drv=vfio-pci unused=iavf,igb_uio\n0000:51:11.1 'Ethernet Adaptive Virtual Function 1889' drv=vfio-pci unused=iavf,igb_uio\n0000:51:21.2 'Ethernet Adaptive Virtual Function 1889' drv=vfio-pci unused=iavf,igb_uio\n0000:51:31.3 'Ethernet Adaptive Virtual Function 1889' drv=vfio-pci unused=iavf,igb_uio\n\nNetwork devices using kernel driver\n===================================\n0000:19:00.0 'BCM57504 NetXtreme-E 10Gb/25Gb/40Gb/50Gb/100Gb/200Gb Ethernet 1751' if=em1 drv=bnxt_en unused=igb_uio,vfio-pci *Active*\n0000:19:00.1 'BCM57504 NetXtreme-E 10Gb/25Gb/40Gb/50Gb/100Gb/200Gb Ethernet 1751' if=em2 drv=bnxt_en unused=igb_uio,vfio-pci\n0000:19:00.2 'BCM57504 NetXtreme-E 10Gb/25Gb/40Gb/50Gb/100Gb/200Gb Ethernet 1751' if=em3 drv=bnxt_en unused=igb_uio,vfio-pci\n0000:19:00.3 'BCM57504 NetXtreme-E 10Gb/25Gb/40Gb/50Gb/100Gb/200Gb Ethernet 1751' if=em4 drv=bnxt_en unused=igb_uio,vfio-pci\n0000:51:00.0 'Ethernet Controller E810-C for QSFP 1592' if=eth13 drv=ice unused=igb_uio,vfio-pci\n0000:51:00.1 'Ethernet Controller E810-C for QSFP 1592' if=rename8 drv=ice unused=igb_uio,vfio-pci\n\n"})}),"\n",(0,t.jsx)(n.h2,{id:"huge-pages",children:"Huge Pages"}),"\n",(0,t.jsx)(n.p,{children:"When a process uses RAM, the CPU marks it as used by that process. For efficiency, the CPU allocates RAM in chunks\u20144K bytes is the default value on many platforms. Those chunks are named pages. Pages can be swapped to disk, etc."}),"\n",(0,t.jsx)(n.p,{children:"Since the process address space is virtual, the CPU and the operating system need to remember which pages belong to which process, and where each page is stored. The more pages you have, the more time it takes to find where memory is mapped. When a process uses 1GB of memory, that's 262144 entries to look up (1GB / 4K). If one page table entry consume 8 bytes, that's 2MB (262144 * 8) to look up."}),"\n",(0,t.jsx)(n.p,{children:"Most current CPU architectures support larger-than-default pages, which give the CPU/OS less entries to look-up."}),"\n",(0,t.jsx)(n.h3,{id:"kernel-parameters-1",children:"Kernel parameters"}),"\n",(0,t.jsx)(n.p,{children:"To enable the huge pages we should add the next kernel parameters:"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"parameter"}),(0,t.jsx)(n.th,{children:"value"}),(0,t.jsx)(n.th,{children:"description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"hugepagesz"}),(0,t.jsx)(n.td,{children:"1G"}),(0,t.jsx)(n.td,{children:"This options allows to set the size of huge pages to 1G"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"hugepages"}),(0,t.jsx)(n.td,{children:"40"}),(0,t.jsx)(n.td,{children:"This is the number of hugepages defined before"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"default_hugepagesz"}),(0,t.jsx)(n.td,{children:"1G"}),(0,t.jsx)(n.td,{children:"This is the default value to get the huge pages"})]})]})]}),"\n",(0,t.jsx)(n.p,{children:"Modify the grub file to add them to the kernel command line:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"vi /etc/default/grub\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'GRUB_CMDLINE_LINUX="intel_iommu=on intel_pstate=passive processor.max_cstate=1 intel_idle.max_cstate=0 iommu=pt usbcore.autosuspend=-1 selinux=0 enforcing=0 nmi_watchdog=0 crashkernel=auto softlockup_panic=0 audit=0 mce=off hugepagesz=1G hugepages=40 hugepagesz=2M hugepages=0 default_hugepagesz=1G kthread_cpus=0,31,32,63 irqaffinity=0,31,32,63 isolcpu=1-30,33-62 skew_tick=1 nohz_full=1-30,33-62 rcu_nocbs=1-30,33-62 rcu_nocb_poll"\n'})}),"\n",(0,t.jsx)(n.h3,{id:"usage-of-huge-pages",children:"Usage of huge pages"}),"\n",(0,t.jsx)(n.p,{children:"In order to use the huge pages we need to mount them:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"mkdir -p /hugepages\nmount -t hugetlbfs nodev /hugepages\n"})}),"\n",(0,t.jsx)(n.p,{children:"Now you could deploy your kubernetes workload creating the resources as well as the volumes:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"... \n resources:\n   requests:\n     memory: \"24Gi\"\n     hugepages-1Gi: 16Gi\n     intel.com/intel_sriov_oru: '4'\n   limits:\n     memory: \"24Gi\"\n     hugepages-1Gi: 16Gi\n     intel.com/intel_sriov_oru: '4'\n...\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"...\nvolumeMounts:\n  - name: hugepage\n    mountPath: /hugepages\n...\nvolumes:\n  - name: hugepage\n    emptyDir:\n      medium: HugePages\n...\n"})}),"\n",(0,t.jsx)(n.h2,{id:"cpu-pinning-configuration",children:"CPU Pinning Configuration"}),"\n",(0,t.jsx)(n.h3,{id:"requirements",children:"Requirements"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["You must have the CPU tuned to the performance profile covered on this ",(0,t.jsx)(n.a,{href:"#cpu-tuned-configuration",children:"section"})]}),"\n",(0,t.jsxs)(n.li,{children:["You must have the RKE2 cluster kubelet configured with the cpu management arguments covered on this ",(0,t.jsx)(n.a,{href:"/docs/product/atip/edge-site#cpu-management-policy",children:"section"})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"use-cpu-pinning-on-kubernetes",children:"Use CPU Pinning on kubernetes"}),"\n",(0,t.jsxs)(n.p,{children:["There are three ways to use that feature using the ",(0,t.jsx)(n.code,{children:"Static Policy"})," defined in kubelet depending on the requests and limits you define on your workload:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"BestEffort"})," QoS Class: If you don't define any request or limit for CPU, the pod will be scheduled on the first CPU available on the system."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["An example to use the ",(0,t.jsx)(n.code,{children:"BestEffort"})," QoS Class could be:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"spec:\n  containers:\n  - name: nginx\n    image: nginx\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"Burstable"})," QoS Class: If you define a request for CPU, which is not equal to the limits, or maybe there is no CPU request."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Examples to use the ",(0,t.jsx)(n.code,{children:"Burstable"})," QoS Class could be:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'spec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n        memory: "200Mi"\n      requests:\n        memory: "100Mi"\n'})}),"\n",(0,t.jsx)(n.p,{children:"or"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'spec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n        memory: "200Mi"\n        cpu: "2"\n      requests:\n        memory: "100Mi"\n        cpu: "1"\n'})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"Guaranteed"})," QoS Class: If you define a request for CPU, which is equal to the limits."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["An example to use the ",(0,t.jsx)(n.code,{children:"Guaranteed"})," QoS Class could be:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'spec:\n  containers:\n    - name: nginx\n      image: nginx\n      resources:\n        limits:\n          memory: "200Mi"\n          cpu: "2"\n        requests:\n          memory: "200Mi"\n          cpu: "2"\n'})}),"\n",(0,t.jsx)(n.h2,{id:"numa-aware-scheduling",children:"NUMA Aware scheduling"}),"\n",(0,t.jsx)(n.p,{children:"Non-Uniform Memory Access or Non-Uniform Memory Architecture (NUMA) is a physical memory design used in SMP (multiprocessors) architecture, where the memory access time depends on the memory location relative to a processor. Under NUMA, a processor can access its own local memory faster than non-local memory, that is, memory local to another processor or memory shared between processors."}),"\n",(0,t.jsx)(n.h3,{id:"identify-numa-nodes",children:"Identify NUMA nodes"}),"\n",(0,t.jsx)(n.p,{children:"To identify the NUMA nodes on your system you can use the next command:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"numactl --hardware\navailable: 1 nodes (0)\nnode 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63\nnode 0 size: 257167 MB\nnode 0 free: 246390 MB\nnode distances:\nnode   0\n  0:  10\n"})}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Note:"})," In this case we have only one NUMA node"]}),"\n",(0,t.jsx)(n.p,{children:"NUMA has to enabled in the BIOS. If dmesg does not have records of numa initialization during bootup, then it is possible that NUMA related messages in the kernel ring buffer might have been overwritten."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"vran-acceleration-intel-acc100",children:"VRAN Acceleration (Intel ACC100)"}),"\n",(0,t.jsx)(n.p,{children:"As communications service providers move from 4G to 5G networks, many are adopting virtualized radio access network (vRAN) architectures for higher channel capacity and easier deployment of edge-based services and applications. vRAN solutions are ideally located to deliver low-latency services with the flexibility to increase or decrease capacity based on the volume of real-time traffic and demand on the network."}),"\n",(0,t.jsx)(n.h3,{id:"kernel-parameters-2",children:"Kernel parameters"}),"\n",(0,t.jsx)(n.p,{children:"To enable the vRAN acceleration we need to enable the following kernel parameters (if not present yet):"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"parameter"}),(0,t.jsx)(n.th,{children:"value"}),(0,t.jsx)(n.th,{children:"description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"iommu"}),(0,t.jsx)(n.td,{children:"pt"}),(0,t.jsx)(n.td,{children:"This option allows to use vfio for the dpdk interfaces"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"intel_iommu"}),(0,t.jsx)(n.td,{children:"on"}),(0,t.jsx)(n.td,{children:"This option enables to use vfio for VFs."})]})]})]}),"\n",(0,t.jsx)(n.p,{children:"Modify the grub file to add them to the kernel command line:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"vi /etc/default/grub\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'GRUB_CMDLINE_LINUX="intel_iommu=on intel_pstate=passive processor.max_cstate=1 intel_idle.max_cstate=0 iommu=pt usbcore.autosuspend=-1 selinux=0 enforcing=0 nmi_watchdog=0 crashkernel=auto softlockup_panic=0 audit=0 mce=off hugepagesz=1G hugepages=40 hugepagesz=2M hugepages=0 default_hugepagesz=1G kthread_cpus=0,31,32,63 irqaffinity=0,31,32,63 isolcpu=1-30,33-62 skew_tick=1 nohz_full=1-30,33-62 rcu_nocbs=1-30,33-62 rcu_nocb_poll"\n'})}),"\n",(0,t.jsx)(n.p,{children:"Then you need to update the grub configuration and reboot the system to apply the changes:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"transactional-update grub.cfg\nreboot\n"})}),"\n",(0,t.jsx)(n.p,{children:"To validate that the parameters are applied after the reboot you can check the command line:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"cat /proc/cmdline\n"})}),"\n",(0,t.jsx)(n.h3,{id:"load-igb_uio-and-vfio-pci-kernel-modules",children:"Load igb_uio and vfio-pci kernel modules"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"modprobe igb_uio\nmodprobe vfio-pci\n"})}),"\n",(0,t.jsx)(n.h3,{id:"get-interface-information-acc100",children:"Get interface information Acc100"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:["Maybe in some cases (depending on the OS) you should add to the path the /sbin/ for the lspci command doing: ",(0,t.jsx)(n.code,{children:"export PATH=$PATH:/sbin/"})]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"lspci | grep -i acc\n8a:00.0 Processing accelerators: Intel Corporation Device 0d5c\n"})}),"\n",(0,t.jsx)(n.h3,{id:"bind-the-pf-with-igb_uio-module",children:"Bind the PF with igb_uio module"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"dpdk-devbind.py -b igb_uio 0000:8a:00.0\n"})}),"\n",(0,t.jsx)(n.h3,{id:"create-the-vfs-from-the-pf",children:"Create the VFs from the PF"}),"\n",(0,t.jsx)(n.p,{children:"To create 2 vfs from the PF and bind with vfio-pci follow the next steps:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"echo 2 > /sys/bus/pci/devices/0000:8a:00.0/max_vfs\ndpdk-devbind.py -b vfio-pci 0000:8b:00.0\n"})}),"\n",(0,t.jsx)(n.h3,{id:"configure-acc100-with-the-proposed-configuration-file",children:"Configure acc100 with the proposed configuration file"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"pf_bb_config ACC100 -c /opt/pf-bb-config/acc100_config_vf_5g.cfg\nTue Jun  6 10:49:20 2023:INFO:Queue Groups: 2 5GUL, 2 5GDL, 2 4GUL, 2 4GDL\nTue Jun  6 10:49:20 2023:INFO:Configuration in VF mode\nTue Jun  6 10:49:21 2023:INFO: ROM version MM 99AD92\nTue Jun  6 10:49:21 2023:WARN:* Note: Not on DDR PRQ version  1302020 != 10092020\nTue Jun  6 10:49:21 2023:INFO:PF ACC100 configuration complete\nTue Jun  6 10:49:21 2023:INFO:ACC100 PF [0000:8a:00.0] configuration complete!\n"})}),"\n",(0,t.jsx)(n.h3,{id:"check-the-new-vfs-created-from-the-fec-pf",children:"Check the new VFs created from the FEC PF:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"dpdk-devbind.py -s\n...\n...\n...\nBaseband devices using DPDK-compatible driver\n=============================================\n0000:8a:00.0 'Device 0d5c' drv=igb_uio unused=vfio-pci\n0000:8b:00.0 'Device 0d5d' drv=vfio-pci unused=igb_uio\n\nOther Baseband devices\n======================\n0000:8b:00.1 'Device 0d5d' unused=igb_uio,vfio-pci\n"})}),"\n",(0,t.jsx)(n.h2,{id:"metal-lb-beta",children:"Metal LB (Beta)"}),"\n",(0,t.jsx)(n.p,{children:"TBC"})]})}function h(e={}){const{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8122:(e,n,i)=>{i.d(n,{Z:()=>t});const t=i.p+"assets/images/multus-3938993e53a38e5e137f93dc7e4e90b3.png"},5063:(e,n,i)=>{i.d(n,{Z:()=>t});const t=i.p+"assets/images/sriov-bafde3df00f7d4faea8ffdcea7245133.png"},1151:(e,n,i)=>{i.d(n,{Z:()=>l,a:()=>o});var t=i(7294);const r={},s=t.createContext(r);function o(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);